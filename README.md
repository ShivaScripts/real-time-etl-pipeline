# ğŸš€ Realâ€‘Time ETL Pipeline  
*A realâ€‘time ETL pipeline leveraging Kafka, Spark, Airflow, and Docker containers.*  

---

## ğŸ“‹ Summary  
This pipeline automatically generates example log messages, sends them through Kafka, saves the raw logs, cleans and analyzes them with Spark, and is scheduled and monitored by Airflow.
- ğŸ”„ **Streaming Ingestion:** Apache Kafka ingests synthetic logs in real time.  
- ğŸ¤– **Data Generation:** Python `Faker` library creates realistic fake log entries.  
- âš¡ **Stream Processing:** Spark Structured Streaming transforms and aggregates logs.  
- ğŸ“† **Workflow Orchestration:** Airflow schedules & monitors your ETL DAG.  
- ğŸ³ **Containerized Deployment:** Docker Compose spins up Kafka, Spark, Airflow, etc.

---
## Architecture Diagram

![Architecture](assets/architecture.png)

---

## ğŸ¥ Demo  
![Pipeline Demo](demo.gif)  
*Placeholder GIF showing logs flowing through Kafka â†’ Spark â†’ Airflow.*

---

## âœ¨ Features  
- **Real-Time Data Ingestion** via Kafka topics  
- **Synthetic Log Generation** with `Faker`  
- **Fault-Tolerant Stream Processing** using Spark (exactly-once semantics)  
- **DAG-Based Scheduling** through Airflow  
- **Oneâ€‘Click Deployment** with Docker Compose  

---

## ğŸ›  Tech Stack  
- **Kafka** â€“ Distributed streaming platform  
- **Spark Structured Streaming** â€“ Scalable, fault-tolerant stream processing  
- **Airflow** â€“ Workflow orchestration and scheduling  
- **Docker & Docker Compose** â€“ Containerization and multi-service orchestration  
- **Python** â€“ Core language for scripts  
- **Faker** â€“ Synthetic data generation library  

---

## ğŸ—‚ï¸ Folder Structure  
